xlab("Gestational Age (in weeks)") +
ylab("Birth Weight (in kilograms)")
cor(weight$BirthWeigh, weight$Mage)
#Reorder Birthweight data columns to have birth weight as last column
weights_ordered <- weight[,c(2,3,4,5,1)]
ggpairs(weights_ordered) + ggtitle('Pairs Plot of Birth Weight Data')
weight.lm <- lm(BirthWeight ~., data = weight)
summary(weight.lm)
?dim
dim(weight)
dim(weight)[1]
weight
weight
View(weight)
dim(weight)[1]
## Read in the data
weight <- read.csv("https://mheaton.byu.edu/docs/files/Stat469/Topics/1%20-%20Independence/1%20-%20IID/InClassCaseStudy/Data/BirthWeights.txt", header = TRUE, sep = " ")
summary(weight)
## Read in the data
weight <- read.csv("https://mheaton.byu.edu/docs/files/Stat469/Topics/1%20-%20Independence/1%20-%20IID/InClassCaseStudy/Data/BirthWeights.txt", header = TRUE, sep = " ")
summary(weight)
# Scatter plot for mothers age and baby birth weight
ggplot(data = weight, mapping = aes(x = Mage, y = BirthWeight)) +
geom_point() +
geom_smooth(se = FALSE) +
ggtitle('Scatterplot of Birth Weight by Age of Mother') +
xlab('Age of Mother') +
ylab('Birth Weight')
#Boxplot for baby birth weight and mother's race
ggplot(data = weight, mapping = aes(x = Race, y = BirthWeight)) +
geom_boxplot() +
ggtitle("Boxplots of Birth Weight by Race") +
xlab("Race") +
ylab("Birth Weight (in kilograms)")
ggplot(data = weight,
mapping = aes(x = Gage, y = BirthWeight, color = Gen)) +
geom_point() +
geom_smooth(se = FALSE) +
ggtitle("Scatterplot of Birth Weight by Gestational Age") +
xlab("Gestational Age (in weeks)") +
ylab("Birth Weight (in kilograms)")
cor(weight$BirthWeigh, weight$Mage)
#Reorder Birthweight data columns to have birth weight as last column
weights_ordered <- weight[,c(2,3,4,5,1)]
ggpairs(weights_ordered) + ggtitle('Pairs Plot of Birth Weight Data')
n <- dim(weight)[1] # number of observations
P <- dim(weight)[2]-1 # total number of explanatory variables
yxbhat <- Y-X%*%beta.hat
s2 <- (t(yxbhat)%*%yxbhat) * (1/(n-P-1))
s2
weight.lm <- lm(BirthWeight ~., data = weight)
summary(weight.lm)
sqrt(s2)
names(weight.lm)
weight.lm <- lm(BirthWeight ~., data = weight)
summary(weight.lm)
fitted(weight.lm)
fitted.values
fitted.values - lm.fitted
resid - lm.resid
View(weight)
View(X)
round(fitted.values - lm.fitted)
round(fitted.values - lm.fitted, 3)
round(resid - lm.resid, 3)
summary(weight.lm)$r.squared
#Scatterplot of the fitted values vs. standardized residuals
ggplot(data=weight,
mapping=aes(x=fitted(weight.lm),
y=resid(weight.lm))) +
geom_point() +
geom_hline(yintercept = 0) +
ggtitle('Fitted Values vs Residual Values') +
xlab('Fitted Values') +
ylab('Standardized Residuals')
#B-P Test
bptest(weight.lm)
# p = 0.338, so we prove that residuals have euqal variace
x.new <- matrix(nrow = 1, c(1,26,37,1,0,0,0)) #create new matrix for prediction
y.pred.new <- x.new %*% beta.hat
y.pred.new
#The predicted value for this baby is 2741.04 grams.
#Confirm that this is what predict.lm() is doing to get the point prediction.
df.newx <- as.data.frame(x.new)
colnames(df.newx) <- colnames(X)
predict.lm(weight.lm,
newdata= data.frame(Mage= 26, Gage= 37, Race="hisp",
Gen="Female"),
interval="prediction", level=0.97)
#Our predicted value 2741.04 grams is between the prediction interval (2126.917, 3355.164) grams.
as.vector(weight[,1])
weight[,1]
Y
n.cv <- 100 #Number of CV studies to run
n.test <- round(dim(weight)[1]*0.3, 0) #Number of observations in a test set
rpmse <- rep(x=NA, times=n.cv)
bias <- rep(x=NA, times=n.cv)
wid <- rep(x=NA, times=n.cv)
cvg <- rep(x=NA, times=n.cv)
for(cv in 1:n.cv){
## Select test observations
n <- dim(weight)[1]
test.obs <- sample(x=1:n, size=n.test)
## Split into test and training sets
test.set <- weight[test.obs,]
train.set <- weight[-test.obs,]
## Fit a lm() using the training data
train.lm <- lm(formula=weight.lm, data=train.set)
## Generate predictions for the test set
my.preds <- predict.lm(train.lm, newdata=test.set, interval="prediction")
## Calculate bias
bias[cv] <- mean(my.preds[,'fit']-test.set[['BirthWeight']])
## Calculate RPMSE
rpmse[cv] <- (test.set[['BirthWeight']]-my.preds[,'fit'])^2 %>% mean() %>% sqrt()
## Calculate Coverage
cvg[cv] <- ((test.set[['BirthWeight']] > my.preds[,'lwr']) & (test.set[['BirthWeight']] < my.pred[,'upr'])) %>% mean()
## Calculate Width
wid[cv] <- (my.pred[,'upr'] - my.preds[,'lwr']) %>% mean()
}
df.newx <- as.data.frame(x.new)
colnames(df.newx) <- colnames(X)
colnames(df.newx)
predict.lm(weight.lm,
newdata= data.frame(Mage= 26, Gage= 37, Race="hisp",
Gen="Female"),
interval="prediction", level=0.99)
x.new <- matrix(nrow = 1, c(1,26,37,1,0,0,0)) #create new matrix for prediction
y.pred.new <- x.new %*% beta.hat
y.pred.new
#The predicted value for this baby is 2741.04 grams.
#Confirm that this is what predict.lm() is doing to get the point prediction.
df.newx <- as.data.frame(x.new)
colnames(df.newx) <- colnames(X)
predict.lm(weight.lm,
newdata= data.frame(Mage= 26, Gage= 37, Race="hisp",
Gen="Female"),
interval="prediction", level=0.97)
#Our predicted value 2741.04 grams is between the prediction interval (2126.917, 3355.164) grams.
n.cv <- 100 #Number of CV studies to run
n.test <- round(dim(weight)[1]*0.3, 0) #Number of observations in a test set
rpmse <- rep(x=NA, times=n.cv)
bias <- rep(x=NA, times=n.cv)
wid <- rep(x=NA, times=n.cv)
cvg <- rep(x=NA, times=n.cv)
for(cv in 1:n.cv){
## Select test observations
n <- dim(weight)[1]
test.obs <- sample(x=1:n, size=n.test)
## Split into test and training sets
test.set <- weight[test.obs,]
train.set <- weight[-test.obs,]
## Fit a lm() using the training data
train.lm <- lm(formula=weight.lm, data=train.set)
## Generate predictions for the test set
my.preds <- predict.lm(train.lm, newdata=test.set, interval="prediction")
## Calculate bias
bias[cv] <- mean(my.preds[,'fit']-test.set[['BirthWeight']])
## Calculate RPMSE
rpmse[cv] <- (test.set[['BirthWeight']]-my.preds[,'fit'])^2 %>% mean() %>% sqrt()
## Calculate Coverage
cvg[cv] <- ((test.set[['BirthWeight']] > my.preds[,'lwr']) & (test.set[['BirthWeight']] < my.pred[,'upr'])) %>% mean()
## Calculate Width
wid[cv] <- (my.pred[,'upr'] - my.preds[,'lwr']) %>% mean()
}
plot.hist <- function(variable){
ggplot()+geom_histogram(mapping=aes(x=variable), bins=30)
}
plot.hist <- function(variable){
ggplot()+geom_histogram(mapping=aes(x=variable), bins=30)
}
plot.hist(bias) +  # Plot for bias
ggtitle('Histogram of Bias') +
xlab('Bias')
plot.hist(rpmse) +# Plot for RPMSE
ggtitle('Histogram of RPMSE') +
xlab('RPMSE')
plot.hist(cvg) +
ggtitle('Histogram of Coverage') +
xlab('Coverage') # Plot for coverage
n.cv <- 100 #Number of CV studies to run
n.test <- round(dim(weight)[1]*0.3, 0) #Number of observations in a test set
rpmse <- rep(x=NA, times=n.cv)
bias <- rep(x=NA, times=n.cv)
wid <- rep(x=NA, times=n.cv)
cvg <- rep(x=NA, times=n.cv)
for(cv in 1:n.cv){
## Select test observations
n <- dim(weight)[1]
test.obs <- sample(x=1:n, size=n.test)
## Split into test and training sets
test.set <- weight[test.obs,]
train.set <- weight[-test.obs,]
## Fit a lm() using the training data
train.lm <- lm(formula=weight.lm, data=train.set)
## Generate predictions for the test set
my.preds <- predict.lm(train.lm, newdata=test.set, interval="prediction")
## Calculate bias
bias[cv] <- mean(my.preds[,'fit']-test.set[['BirthWeight']])
## Calculate RPMSE
rpmse[cv] <- (test.set[['BirthWeight']]-my.preds[,'fit'])^2 %>% mean() %>% sqrt()
## Calculate Coverage
cvg[cv] <- ((test.set[['BirthWeight']] > my.preds[,'lwr']) & (test.set[['BirthWeight']] < my.pred[,'upr'])) %>% mean()
## Calculate Width
wid[cv] <- (my.pred[,'upr'] - my.preds[,'lwr']) %>% mean()
}
s2#print s^2 value
sqrt(s2)
summary(weight.lm)
head(weight.lm)
head(summary(weight.lm))
names(summary(weight.lm))
names(weight.lm)
n.cv <- 100 #Number of CV studies to run
n.test <- round(dim(weight)[1]*0.3, 0) #Number of observations in a test set
rpmse <- rep(x=NA, times=n.cv)
bias <- rep(x=NA, times=n.cv)
wid <- rep(x=NA, times=n.cv)
cvg <- rep(x=NA, times=n.cv)
for(cv in 1:n.cv){
## Select test observations
n <- dim(weight)[1]
test.obs <- sample(x=1:n, size=n.test)
## Split into test and training sets
test.set <- weight[test.obs,]
train.set <- weight[-test.obs,]
## Fit a lm() using the training data
train.lm <- lm(formula=weight.lm, data=train.set)
## Generate predictions for the test set
my.preds <- predict.lm(train.lm, newdata=test.set, interval="prediction")
## Calculate bias
bias[cv] <- mean(my.preds[,'fit']-test.set[['BirthWeight']])
## Calculate RPMSE
rpmse[cv] <- (test.set[['BirthWeight']]-my.preds[,'fit'])^2 %>% mean() %>% sqrt()
## Calculate Coverage
cvg[cv] <- ((test.set[['BirthWeight']] > my.preds[,'lwr']) & (test.set[['BirthWeight']] < my.pred[,'upr'])) %>% mean()
## Calculate Width
wid[cv] <- (my.pred[,'upr'] - my.preds[,'lwr']) %>% mean()
}
dim(weight)[2]
dim(weight)[2]-1
n.cv <- 100 #Number of CV studies to run
n.test <- round(dim(weight)[1]*0.3, 0) #Number of observations in a test set
rpmse <- rep(x=NA, times=n.cv)
bias <- rep(x=NA, times=n.cv)
wid <- rep(x=NA, times=n.cv)
cvg <- rep(x=NA, times=n.cv)
for(cv in 1:n.cv){
## Select test observations
n <- dim(weight)[1]
test.obs <- sample(x=1:n, size=n.test)
## Split into test and training sets
test.set <- weight[test.obs,]
train.set <- weight[-test.obs,]
## Fit a lm() using the training data
train.lm <- lm(formula=weight.lm, data=train.set)
## Generate predictions for the test set
my.preds <- predict.lm(train.lm, newdata=test.set, interval="prediction")
## Calculate bias
bias[cv] <- mean(my.preds[,'fit']-test.set[['BirthWeight']])
## Calculate RPMSE
rpmse[cv] <- (test.set[['BirthWeight']]-my.preds[,'fit'])^2 %>% mean() %>% sqrt()
## Calculate Coverage
cvg[cv] <- ((test.set[['BirthWeight']] > my.preds[,'lwr']) & (test.set[['BirthWeight']] < my.pred[,'upr'])) %>% mean()
## Calculate Width
wid[cv] <- (my.pred[,'upr'] - my.preds[,'lwr']) %>% mean()
}
cv <- 1
## Select test observations
n <- dim(weight)[1]
test.obs <- sample(x=1:n, size=n.test)
## Split into test and training sets
test.set <- weight[test.obs,]
train.set <- weight[-test.obs,]
## Fit a lm() using the training data
train.lm <- lm(formula=weight.lm, data=train.set)
## Generate predictions for the test set
my.preds <- predict.lm(train.lm, newdata=test.set, interval="prediction")
my.preds
head(my.preds)
## Calculate bias
bias[cv] <- mean(my.preds[,'fit']-test.set[['BirthWeight']])
## Calculate RPMSE
rpmse[cv] <- (test.set[['BirthWeight']]-my.preds[,'fit'])^2 %>% mean() %>% sqrt()
## Calculate Coverage
cvg[cv] <- ((test.set[['BirthWeight']] > my.preds[,'lwr']) & (test.set[['BirthWeight']] < my.pred[,'upr'])) %>% mean()
## Calculate Coverage
cvg[cv] <- ((test.set[['BirthWeight']] > my.preds[,'lwr']) & (test.set[['BirthWeight']] < my.preds[,'upr'])) %>% mean()
## Calculate Width
wid[cv] <- (my.preds[,'upr'] - my.preds[,'lwr']) %>% mean()
n.cv <- 100 #Number of CV studies to run
n.test <- round(dim(weight)[1]*0.3, 0) #Number of observations in a test set
rpmse <- rep(x=NA, times=n.cv)
bias <- rep(x=NA, times=n.cv)
wid <- rep(x=NA, times=n.cv)
cvg <- rep(x=NA, times=n.cv)
for(cv in 1:n.cv){
## Select test observations
n <- dim(weight)[1]
test.obs <- sample(x=1:n, size=n.test)
## Split into test and training sets
test.set <- weight[test.obs,]
train.set <- weight[-test.obs,]
## Fit a lm() using the training data
train.lm <- lm(formula=weight.lm, data=train.set)
## Generate predictions for the test set
my.preds <- predict.lm(train.lm, newdata=test.set, interval="prediction")
## Calculate bias
bias[cv] <- mean(my.preds[,'fit']-test.set[['BirthWeight']])
## Calculate RPMSE
rpmse[cv] <- (test.set[['BirthWeight']]-my.preds[,'fit'])^2 %>% mean() %>% sqrt()
## Calculate Coverage
cvg[cv] <- ((test.set[['BirthWeight']] > my.preds[,'lwr']) & (test.set[['BirthWeight']] < my.preds[,'upr'])) %>% mean()
## Calculate Width
wid[cv] <- (my.preds[,'upr'] - my.preds[,'lwr']) %>% mean()
}
hist(rpmse)
ggplot() +
geom_histogram(mapping = aes(x=bias)),
ggplot() +
geom_histogram(mapping = aes(x=bias)),
ggplot() + geom_histogram(mapping = aes(x=bias)), bins = 20)
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 20)
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 30)
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 20, binwidth = 0.3)
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 20, binwidth = 2)
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 20, binwidth = 10)
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 20, binwidth = 15)
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 20, binwidth = 10)
#Plot  histogram for bias
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 20, binwidth = 10) +
ggtitle('Histogram of Bias') +
xlab('Bias')
#Plot  histogram for bias
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 30, binwidth = 10) +
ggtitle('Histogram of Bias') +
xlab('Bias')
#Plot  histogram for bias
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 20, binwidth = 10) +
ggtitle('Histogram of Bias') +
xlab('Bias')
ggplot() + geom_histogram(mapping = aes(x=rpmse), bins = 20, binwidth = 10) +
ggtitle('Histogram of RPMSE') +
xlab('RPMSE')
#Plot histogram for RPMSE, coverage and width
ggplot() + geom_histogram(mapping = aes(x=rpmse)) +
ggtitle('Histogram of RPMSE') +
xlab('RPMSE')
#Plot histogram for bias
ggplot() + geom_histogram(mapping = aes(x=bias)) +
ggtitle('Histogram of Bias') +
xlab('Bias')
#Plot histogram for bias
ggplot() + geom_histogram(mapping = aes(x=bias),bins = 20) +
ggtitle('Histogram of Bias') +
xlab('Bias')
#Plot histogram for bias
ggplot() + geom_histogram(mapping = aes(x=bias), bins = 30) +
ggtitle('Histogram of Bias') +
xlab('Bias')
#Plot histogram for RPMSE, coverage and width
ggplot() + geom_histogram(mapping = aes(x=rpmse)) +
ggtitle('Histogram of RPMSE') +
xlab('RPMSE')
#Plot histogram for RPMSE, coverage and width
ggplot() + geom_histogram(mapping = aes(x=rpmse), bins = 20) +
ggtitle('Histogram of RPMSE') +
xlab('RPMSE')
#Plot histogram for coverage
ggplot() + geom_histogram(mapping = aes(x=cvg), bins = 20) +
ggtitle('Histogram of RPMSE') +
xlab('RPMSE')
#Plot histogram for coverage
ggplot() + geom_histogram(mapping = aes(x=cvg)) +
ggtitle('Histogram of RPMSE') +
xlab('RPMSE')
, bins = 20
ggplot() + geom_histogram(mapping = aes(x=cvg), bins = 20) +
ggtitle('Histogram of RPMSE') +
xlab('RPMSE')
#Plot histogram for width
ggplot() + geom_histogram(mapping = aes(x=wid), bins = 20) +
ggtitle('Histogram of Width') +
xlab('Width')
#Plot histogram for coverage
ggplot() + geom_histogram(mapping = aes(x=cvg), bins = 20) +
ggtitle('Histogram of Coverage') +
xlab('Coverage')
summary(weight.lm)
coef(summary(weight.lm))["Mage", "t vale"]
coef(summary(weight.lm))["Mage", "t value"]
summary(weight.lm)
coef(summary(weight.lm))["Mage", "t value"]
summary(weight.lm)
coef(summary(weight.lm))["Mage", "t value"]
#The t-statistic for the test H0: βMage=0 is -2.259
t.stat <- coef(summary(weight.lm))["Mage", "t value"]
round(t.stat)
round(t.stat, 3)
p.value <- coef(summary(weight.lm))["Mage", "Pr(>|t|)"]
p.value
round(p.value, 3)
confint(weight.lm, level = .90)
confint(weight.lm, level = .90)[2,2]
confint(weight.lm, level = .90)[2]
confint(weight.lm, level = .90)
confint(weight.lm, level = .90)["Mage"]
confint(weight.lm, level = .90)["Mage", "5%"]
names(confint(weight.lm, level = .90))
confint(weight.lm, level = .90)
summary(conf)
conf <- confint(weight.lm, level = .90)
summary(conf)
conf["Mage"]
?list
list(conf)
conf["Mage", "5%"]
conf["Mage", "5 %"]
confint(weight.lm, level = .90)
conf["Mage", "95 %"]
c(conf["Mage", "5 %"], conf["Mage", "95 %"])
conf.mage <- c(conf["Mage", "5 %"], conf["Mage", "95 %"])
conf.mage
list(lower.bound = conf['Mage', '5 %'], upper.bound = conf['Mage', '95 %'])
conf.mage
conf <- confint(weight.lm, level = .90)
conf.mage <- c(conf["Mage", "5 %"], conf["Mage", "95 %"])
conf.mage
confint(weight.lm, level = .90)
conf <- confint(weight.lm, level = 0.90)
conf.mage <- c(conf["Mage", "5 %"], conf["Mage", "95 %"])
conf.mage
full.lm <- weight.lm
reduced.lm <- lm(BirthWeight ~ Mage + Gage + as.factor(Gen), data=weight)
anova(full.lm, reduced.lm) # Since the p-value on the F-stat is 0.0001 < 0.05, we
baby1 <-  matrix(nrow=7,ncol=1, data=c(1, 24, 40, 0, 0, 1, 1))
baby1 <- matrix(nrow=7,ncol=1, data=c(1, 24, 40, 0, 0, 1, 1))]
baby1 <- matrix(nrow=7,ncol=1, data=c(1, 24, 40, 0, 0, 1, 1))
baby2 <- matrix(nrow=7,ncol=1, data=c(1, 34, 33, 0, 0, 1, 1))
# (a1−a2)′β=a′β
baby1 -baby2
t(a)
baby1 <- matrix(nrow=7,ncol=1, data=c(1, 24, 40, 0, 0, 1, 1))
baby2 <- matrix(nrow=7,ncol=1, data=c(1, 34, 33, 0, 0, 1, 1))
# (a1−a2)′β=a′β
a <- baby1 -baby2
t(a)
a.transpose <- t(a)
my.test <- glht(mymodel, linfct=a.transpose, alternative="two.sided")
library(multcomp) #generalized linear hypothesis test
install.packages("multcomp")
library(ggplot2) # Import GG Plot for professional graphs
library(GGally) #Improt pairs plot
library(car) #Import avPlot
library(MASS) #For standardized residuals plot
library(lmtest) # For B-P test
library(magrittr) #pipe command
library(multcomp) #generalized linear hypothesis test
baby1 <- matrix(nrow=7,ncol=1, data=c(1, 24, 40, 0, 0, 1, 1))
baby2 <- matrix(nrow=7,ncol=1, data=c(1, 34, 33, 0, 0, 1, 1))
# (a1−a2)′β=a′β
a <- baby1 -baby2
a.transpose <- t(a)
my.test <- glht(mymodel, linfct=a.transpose, alternative="two.sided")
my.test <- glht(weight.lm, linfct=a.transpose, alternative="two.sided")
summary(my.test)
confint(my.test, level = 0.94)
baby1 <- matrix(nrow=7,ncol=1, data=c(1, 24, 40, 0, 0, 1, 1))
baby2 <- matrix(nrow=7,ncol=1, data=c(1, 34, 33, 0, 0, 1, 1))
# (a1−a2)′β=a′β
a <- baby1 -baby2
a.transpose <- t(a)
my.test <- glht(weight.lm, linfct=a.transpose, alternative="two.sided")
summary(my.test) # t-test
confint(my.test, level = 0.94) # 94% confidence interval
R.version.string
bike.train <- vroom("../Bikesharing/train.csv")
bike.test <- vroom("../Bikesharing/test.csv")
bike <- bind_rows(train = bike.train, test = bike.test, .id = "id")
# combine train and test dataset and then create first column name id (bind_rows :tidyverse)
# use "bike %>% filter(id == "train")" to filter bike.train data
## Drop casual and registered
bike <- bike %>% select(-casual, -registered)
## Feature Engineering
bike$hour <- hour(bike$datetime) %>% as.factor()
bike$times <- as.POSIXct(strftime(ymd_hms(bike$datetime), format="%H:%M:%S"), format="%H:%M:%S") %>% as.factor()
bike$day   <- wday(ymd_hms(bike$datetime), label=TRUE) %>% as.factor()
library(tidyverse)
library(DataExplorer)
library(caret)
library(vroom)
library(lubridate)
bike.train <- vroom("../Bikesharing/train.csv")
bike.test <- vroom("../Bikesharing/test.csv")
bike <- bind_rows(train = bike.train, test = bike.test, .id = "id")
# combine train and test dataset and then create first column name id (bind_rows :tidyverse)
# use "bike %>% filter(id == "train")" to filter bike.train data
## Drop casual and registered
bike <- bike %>% select(-casual, -registered)
bike$hour <- hour(bike$datetime) %>% as.factor()
bike$times <- as.POSIXct(strftime(ymd_hms(bike$datetime), format="%H:%M:%S"), format="%H:%M:%S") %>% as.factor()
bike$day   <- wday(ymd_hms(bike$datetime), label=TRUE) %>% as.factor()
bike
bike$day
bike$weather <- as.factor(bike$weather)
git config --global user.email "chichiamiao@gmail.com"
git config --global user.email "chichiamiao@gmail.com"
git config --global -l
git config
$ git commit
git commit
$ git config user.email "Your@emailaddres.com"
$ git config user.name "Your name"
